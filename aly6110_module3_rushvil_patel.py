# -*- coding: utf-8 -*-
"""ALY6110_Module3_Rushvil Patel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TWR2DS1bKI7BBNWLdfnXoeNPwySSdNSb
"""

import pandas as pd

# innstall java
!apt-get install openjdk-8-jdk-headless -qq > /dev/null

# install spark (change the version number if needed)
!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz

# unzip the spark file to the current folder
!tar xf spark-3.0.0-bin-hadoop3.2.tgz

# set your spark folder to your system path environment. 
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.0.0-bin-hadoop3.2"


# install findspark using pip
!pip install -q findspark

import findspark
findspark.init()
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()

df=spark.sql("show databases")
df.show()

from google.colab import files
files.upload()

BH = spark.read.csv('BostonHousing.csv',inferSchema=True, header=True)

BH.printSchema

BH.show()

BH.show(5)

BH.count()

BH.schema

BH = BH.drop('b')

BH.show()

from pyspark.sql.functions import round,col
for c in BH.columns:
  BH = BH.withColumn(c,round(c,2))

BH.show()

import pandas as pd
import pyspark.sql
from pyspark.sql.functions import *
from pyspark.sql.types import *

BH = BH.withColumn("Age10", BH.age*1.10)

BH.show()

BH=BH.withColumn("Age10",col("Age10").cast("integer"))

agelist = BH.select("Age10")

agelist

agelist=BH.select("age").rdd.flatMap(lambda x: x).collect()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import numpy as np
## To show plots in this document instead of a window we can't see
# %matplotlib inline

import matplotlib.pyplot as plt
num_bins = 100
n, bins, patches = plt.hist(agelist,
                            num_bins,
                            facecolor = 'green')

BH.summary().show()

import pyspark
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()

df.show()

df_pd = BH.toPandas()

df_pd

df_pd.tail

df_pd.tail(5)